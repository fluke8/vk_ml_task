{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_target_split(data): #выделение признаков и целевой переменной\n",
    "    X = data.drop(['target'], axis=1)\n",
    "    y = data['target']\n",
    "    return X, y\n",
    "\n",
    "def test_model(model, X_train, X_test, y_train, y_test): #тестирование модели\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict_proba(X_test)[:,1]\n",
    "    validation_ndcg = ndcg_score([y_test], [predictions])\n",
    "    print(f'Model: {model.__class__}\\nNDCG on validation set: {validation_ndcg}\\n\\n')\n",
    "\n",
    "def scaling(X_train, X_test): #масштабирование признаков\n",
    "    sc = StandardScaler()\n",
    "    X_train_scaled = sc.fit_transform(X_train)\n",
    "    X_test_scaled = sc.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def add_context(data): #добавление контекста об остальных объектах в группе\n",
    "    features = data.drop(['search_id'], axis=1).columns\n",
    "    context_of_group = pd.DataFrame()\n",
    "\n",
    "    context_ways =['min','max','mean','median']\n",
    "\n",
    "    for context_trainsform in context_ways:\n",
    "        context_of_group = pd.concat([context_of_group, data.groupby('search_id')[features].transform(context_trainsform).add_suffix(\"_\"+context_trainsform)], axis=1)\n",
    "\n",
    "    return pd.concat([data, context_of_group], axis=1).drop('search_id', axis=1)\n",
    "\n",
    "def find_const_features(X_train, X_test): #выделение константных признаков\n",
    "    constant_columns_train = X_train.loc[:, X_train.nunique() == 1].columns.to_list()\n",
    "    constant_columns_test = X_test.loc[:, X_test.nunique() == 1].columns.to_list()\n",
    "\n",
    "    if constant_columns_train == constant_columns_test:\n",
    "        constant_columns = constant_columns_train\n",
    "    else:\n",
    "        raise Exception(\"!!!\")\n",
    "    return constant_columns\n",
    "\n",
    "def find_cat_features(X_train, X_test): #выделение категориальных признаков\n",
    "    categorical_columns_train = X_train.loc[:, (1 < X_train.nunique()) & (X_train.nunique() <= 10)].columns.to_list()\n",
    "    categorical_columns_test = X_test.loc[:, (1 < X_test.nunique()) & (X_test.nunique() <= 9)].columns.to_list()\n",
    "\n",
    "    if categorical_columns_train == categorical_columns_test:\n",
    "        categorical_columns = categorical_columns_train\n",
    "    else:\n",
    "        raise Exception(\"!!!\")\n",
    "    return categorical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test_df.csv')\n",
    "train = pd.read_csv('train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = sample_target_split(train)\n",
    "X_test, y_test = sample_target_split(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_columns = find_const_features(X_train, X_test)\n",
    "categorical_columns = find_cat_features(X_train, X_test)\n",
    "\n",
    "X_train = X_train.drop(constant_columns, axis=1)\n",
    "X_test = X_test.drop(constant_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols=categorical_columns)\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = add_context(X_train)\n",
    "X_test = add_context(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = scaling(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fluke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "NDCG on validation set: 0.5238461260485848\n",
      "\n",
      "\n",
      "Model: <class 'catboost.core.CatBoostClassifier'>\n",
      "NDCG on validation set: 0.6260610646995569\n",
      "\n",
      "\n",
      "Model: <class 'sklearn.dummy.DummyClassifier'>\n",
      "NDCG on validation set: 0.3899032693596343\n",
      "\n",
      "\n",
      "Model: <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "NDCG on validation set: 0.37889392362474755\n",
      "\n",
      "\n",
      "Model: <class 'sklearn.svm._classes.SVC'>\n",
      "NDCG on validation set: 0.4335656749473137\n",
      "\n",
      "\n",
      "Model: <class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "NDCG on validation set: 0.5008501123213425\n",
      "\n",
      "\n",
      "Model: <class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "NDCG on validation set: 0.5307288562116922\n",
      "\n",
      "\n",
      "Model: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "NDCG on validation set: 0.4888098195053024\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_classifiers = [LogisticRegression(), CatBoostClassifier(verbose=False), DummyClassifier(strategy='most_frequent'), KNeighborsClassifier(), SVC(probability=True), \\\n",
    "                DecisionTreeClassifier(), GradientBoostingClassifier(), RandomForestClassifier(),]\n",
    "\n",
    "for model in list_classifiers:\n",
    "    test_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6260610646995569"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = CatBoostClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "predictions = clf.predict_proba(X_test)\n",
    "ndcg_score([y_test.values], [predictions[:,1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
